{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EECS 484 Final Project Chaitanya Kolluru.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"FeIDZ83N1ILj","colab_type":"text"},"cell_type":"markdown","source":["*U-net to segment endothelial cells in specular microscopy images*\n","\n","Include libraries"]},{"metadata":{"id":"0CCRwXuL1US2","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import random as rn\n","import glob\n","import re"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PbuhmvE76mVZ","colab_type":"text"},"cell_type":"markdown","source":["Configure and start a tensorflow session"]},{"metadata":{"id":"4r2M2fIa6qB7","colab_type":"code","colab":{}},"cell_type":"code","source":["session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Hq1Sfiq96xTB","colab_type":"text"},"cell_type":"markdown","source":["Import keras specific classes"]},{"metadata":{"id":"EZagbtZn64lr","colab_type":"code","outputId":"da6d9f6e-edf6-49a0-9893-065656fa3603","executionInfo":{"status":"ok","timestamp":1544575988925,"user_tz":300,"elapsed":395,"user":{"displayName":"Chaitanya Kolluru","photoUrl":"https://lh6.googleusercontent.com/-MQKYUBE5RV0/AAAAAAAAAAI/AAAAAAAAAC4/izr2wv46QEg/s64/photo.jpg","userId":"12376537687734641634"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from keras.models import *\n","from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D, concatenate\n","from keras.optimizers import *\n","from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","from keras import backend as keras\n","import argparse\n","from keras.utils import plot_model\n","import keras\n","from keras import backend as K\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"5WfSFY6g6-rz","colab_type":"text"},"cell_type":"markdown","source":["Set the session in keras"]},{"metadata":{"id":"LC_zXU1G7Dib","colab_type":"code","outputId":"bf393fbe-1571-42fb-b905-ee0069d2c31f","executionInfo":{"status":"ok","timestamp":1544575991126,"user_tz":300,"elapsed":485,"user":{"displayName":"Chaitanya Kolluru","photoUrl":"https://lh6.googleusercontent.com/-MQKYUBE5RV0/AAAAAAAAAAI/AAAAAAAAAC4/izr2wv46QEg/s64/photo.jpg","userId":"12376537687734641634"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["K.set_session(sess)\n","print (keras.__version__)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["2.2.4\n"],"name":"stdout"}]},{"metadata":{"id":"1jU2i4LVB95s","colab_type":"text"},"cell_type":"markdown","source":["Mount google drive to access training and testing images and labels"]},{"metadata":{"id":"jDjATIofLnX0","colab_type":"code","outputId":"ad90e935-4d9d-4724-bf9b-27c8560333d7","executionInfo":{"status":"ok","timestamp":1544576026803,"user_tz":300,"elapsed":33852,"user":{"displayName":"Chaitanya Kolluru","photoUrl":"https://lh6.googleusercontent.com/-MQKYUBE5RV0/AAAAAAAAAAI/AAAAAAAAAC4/izr2wv46QEg/s64/photo.jpg","userId":"12376537687734641634"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"cell_type":"code","source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"id":"QldY8wC3MgYo","colab_type":"text"},"cell_type":"markdown","source":["Define the loss function to train the neural network\n","\n","We will use a weighted form the cross entropy loss function\n","\n","(Less commonly seen classes will have heigher weights)\n","\n","Cell border pixels are weighted nearly 4 times more as compared to other pixels"]},{"metadata":{"id":"mImpX2aIMrKP","colab_type":"code","colab":{}},"cell_type":"code","source":["def weighted_binary_crossentropy(y_true, y_pred):\n","\n","\ty_true_f = K.flatten(y_true)\n","\ty_pred_f = K.flatten(y_pred)\n","\n","\tbinary_crossentropy = K.binary_crossentropy(y_true_f, y_pred_f)\n","\tweighted_vector = y_true_f * 0.21 + (1. - y_true_f) * 0.79\n","\tweighted_binary_crossentropy_loss = weighted_vector * binary_crossentropy\n","\n","\treturn K.mean(weighted_binary_crossentropy_loss)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"91MPXaiJRm-8","colab_type":"text"},"cell_type":"markdown","source":["Helper function to sort images in the right order\n","\n","For example, 1.bmp, 2.bmp, 3.bmp instead of 1.bmp, 10.bmp, 11.bmp etc."]},{"metadata":{"id":"WUqUeMuLRxIH","colab_type":"code","colab":{}},"cell_type":"code","source":["def natural_keys(text):\n","\n","    # Assumes that the path is of the form /content/.../1.jpg\n","    c = re.split('(/\\d+)', text)\n","    print(c)\n","    return int(c[1].split('/')[1])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EP9e2YiP7M43","colab_type":"text"},"cell_type":"markdown","source":["Define the U-Net class, will contain routines to read/write data, train/test networks\n","\n","Object to this class will be instantiated in __main__\n","\n","Specify location to the training and testing data in data_dir variable\n","\n","__load_data__ reads the training images, labels and testing images from the google drive\n","\n","__get_unet__ specifies the network architecture for U-net\n","\n","__train_and_test__ trains and tests the neural network"]},{"metadata":{"id":"t6qp6Lkf7f5f","colab_type":"code","outputId":"b958aab5-3bde-4a06-f3c3-7f0481d127c6","colab":{"base_uri":"https://localhost:8080/","height":1761},"executionInfo":{"status":"error","timestamp":1544576128859,"user_tz":300,"elapsed":357,"user":{"displayName":"Chaitanya Kolluru","photoUrl":"https://lh6.googleusercontent.com/-MQKYUBE5RV0/AAAAAAAAAAI/AAAAAAAAAC4/izr2wv46QEg/s64/photo.jpg","userId":"12376537687734641634"}}},"cell_type":"code","source":["class myUnet(object):\n","\n","    def __init__(self):\n","\n","        self.data_dir = '/content/drive/My Drive/Colab Notebooks/'\n","    \n","    def load_data(self):\n","\n","        # Augment the training images and labels, because 34 training images is a small number of images for deep learning methods\n","        datagen_args = dict(rotation_range=0.2,\n","                            width_shift_range=0.05,\n","                            height_shift_range=0.05,\n","                            shear_range= 0.05,\n","                            zoom_range=0.05,\n","                            horizontal_flip=True,\n","                            fill_mode='nearest',\n","                            rescale=1./255)\n","        \n","        image_datagen = ImageDataGenerator(**datagen_args)\n","        labels_datagen = ImageDataGenerator(**datagen_args)\n","\n","        \n","        # Load training images and labels from the respective directories\n","        image_generator = image_datagen.flow_from_directory(self.data_dir + 'data/train/image/', color_mode='grayscale', class_mode=None, seed=1, batch_size=1, target_size=(480, 320))\n","        labels_generator = labels_datagen.flow_from_directory(self.data_dir + 'data/train/label/', color_mode='grayscale', class_mode=None, seed=1, batch_size=1, target_size=(480, 320))\n","        \n","        # Find all test images from the data folder\n","        self.test_imgs_list = glob.glob(self.data_dir + 'data/test/image/*.bmp')\n","\n","        # Sort so that the list is 1.jpg, 2.jpg etc. and not 1.jpg, 11.jpg etc.\n","        self.test_imgs_list.sort(key=natural_keys)\n","\n","        # Read test image files and load them into a numpy array\n","        imgs_test_stack = np.zeros((len(self.test_imgs_list), 480, 320))\n","        for i in np.arange(len(self.test_imgs_list)):\n","            imgs_test_stack[i,:,:] = img_to_array(load_img(self.test_imgs_list[i]))[:,:,1]/255\n","        \n","        print('%d EC test images found' %(len(self.test_imgs_list)))\n","        \n","        #adds a dimension of 1 at the end\n","        imgs_test_stack = np.expand_dims(imgs_test_stack, axis=-1)\n","\n","        return image_generator, labels_generator, imgs_test_stack\n","      \n","    def get_unet(self):\n","\n","        # Neural network architecture\n","        # Based on the U-Net described here: https://arxiv.org/abs/1505.04597\n","        \n","        # Input layer shape\n","        inputs = Input((480, 320, 1))        \n","\n","        # First Encoding Block\n","        # Convolutional layers of 128 filters each, learning 3x3 kernel\n","        # ReLU activation. Kernel weights initialized as 2/sqrt(fan_in), \n","        # where fan_in is the number of units feeding into this network.\n","        # Maximum pooling \"pools\" a 2x2 area and picks the maximum value\n","        # Gives some form of spatial invariance\n","        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","        # Second Encoding block\n","        # Same as previous, but with more filters learnt (256 vs. 128)\n","        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","        # Third Encoding Block\n","        # Dropout (connections are randomly dropped in the network)\n","        # Proportion of connections dropped is 0.5\n","        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","        drop4 = Dropout(0.5)(conv4)\n","        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","        # Fourth Encoding Block\n","        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","        drop5 = Dropout(0.5)(conv5)\n","\n","        # First Decoding (Upsampling) Block\n","        # Transposed convolutions with kernel size (2,2)\n","        # Subsequent concatenation from lower encoding block outputs\n","        # Two convolutional layers\n","        up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","        merge6 = concatenate([drop4, up6], axis=3)\n","        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","\n","        # Second Decoding Block\n","        up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","        merge7 = concatenate([conv3, up7], axis=3)\n","        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","\n","        # Third Decoding Block\n","        up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","        merge8 = concatenate([conv2, up8], axis=3)\n","        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","        conv8 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","        conv9 = Conv2D(1, 1, activation = 'sigmoid')(conv8)\n","\n","        # Define the inputs and outputs to the network\n","        model = Model(inputs = inputs, outputs = conv9)\n","\n","        # Use the weighted cross entropy loss function as described above\n","        # Adam optimizer is used with a learning rate of 1e-4\n","        model.compile(optimizer = Adam(lr = 1e-4), loss = weighted_binary_crossentropy,  metrics = ['accuracy'])\n","\n","        model.summary()\n","\n","        return model\n","\n","    def train_and_test(self):\n","\n","            print('-' * 30)\n","            print('Training on EC microscopy images')\n","            print('-' * 30)\n","\n","            print('Loading training data (EC cells in microscopy images)')\n","            imgs_train, imgs_train_labels, imgs_test = self.load_data()\n","            print('Loaded training data (EC cells in microscopy images) \\n')\n","\n","            # Get the neural network architecture\n","            print('Loading network architecture')\n","            model = self.get_unet()\n","            print('Loaded network architecture \\n')\n","\n","            # Create a checkpoint to save the network weights to a file. Loss on the validation set will be monitored\n","            model_checkpoint = ModelCheckpoint(self.data_dir + 'unet_train.hdf5', monitor='loss',verbose=1, save_best_only=True)\n","\n","            # Fit the model to the training data\n","            print('Fitting model to train dataset')\n","            model.fit_generator(zip(imgs_train, imgs_train_labels), steps_per_epoch=32, epochs=5, verbose=1, shuffle=True, callbacks=[model_checkpoint])\n","\n","            print('-' * 30)\n","            print('Test on unseen EC microscopy images')\n","            print('-' * 30)\n","\n","            # Load the network weights\n","            print('Loading network weights from unet_train.hdf5 file')\n","            model.load_weights(self.data_dir + 'unet_train.hdf5')\n","            print('Loaded weights from the pre-trained network \\n')\n","\n","            # Predict on the test images\n","            imgs_test_predictions = model.predict(imgs_test, batch_size=1, verbose=1)\n","            print('Predicted on test EC images')\n","\n","            # Save predictions to the results folder\n","            print('Saving predictions on test images to results folder in the current directory')\n","            for i in np.arange(imgs_test_predictions.shape[0]):\n","              \n","              img_test_prediction = array_to_img(imgs_test_predictions[i,:,:])\n","              filename_start_index = self.test_imgs_list[i].rfind('/')\n","\n","              img_test_prediction.save(self.data_dir + 'results/%s' %(self.test_imgs_list[i][filename_start_index+1:]))\n","\n","if __name__ == '__main__':\n","\n","    # Make an object of myUnet class\n","    myunet = myUnet()\n","\n","    # Train and test the U-Net network as needed\n","    myunet.train_and_test()\n","    "],"execution_count":8,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-0d6b49c211f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m# Train and test the U-Net network as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mmyunet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-0d6b49c211f9>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# Fit the model to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fitting model to train dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs_train_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}